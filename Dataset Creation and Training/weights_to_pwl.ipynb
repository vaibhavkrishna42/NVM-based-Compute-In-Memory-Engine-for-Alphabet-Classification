{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 16)\n"
     ]
    }
   ],
   "source": [
    "L1_weights = torch.load('L1_Weights.pt', weights_only=True).int().numpy()\n",
    "L1_bias = torch.load('L1_Bias.pt', weights_only=True).int().numpy()\n",
    "\n",
    "L2_weights = torch.load('L2_Weights.pt', weights_only=True).int().numpy()\n",
    "L2_bias = torch.load('L2_Bias.pt', weights_only=True).int().numpy()\n",
    "\n",
    "img = torch.load('Image_input.pt', weights_only=True).int().numpy()\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 2 2 0 2 0 0]\n"
     ]
    }
   ],
   "source": [
    "y1 = img[54] @ L1_weights + L1_bias\n",
    "print(y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 2 5 3]\n"
     ]
    }
   ],
   "source": [
    "y2 = np.array([1, 1, 1, 1, 0, 1, 0, 0]) @ L2_weights + L2_bias \n",
    "\n",
    "print(y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 1 1 1]\n",
      " [0 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 1 0 0]\n",
      " [1 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 1]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 1 1 0 0 0 0 0]\n",
      " [0 1 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [1 0 0 1 0 0 0 0]\n",
      " [1 0 0 0 1 1 0 1]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0]\n",
      " [1 0 0 0 1 1 0 1]]\n"
     ]
    }
   ],
   "source": [
    "print(L1_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(L1_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 1 1 1]\n",
      " [0 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 1 0 0]\n",
      " [1 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 1]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 1 1 0 0 0 0 0]\n",
      " [0 1 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [1 0 0 1 0 0 0 0]\n",
      " [1 0 0 0 1 1 0 1]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0]\n",
      " [1 0 0 0 1 1 0 1]\n",
      " [0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "w1_prog = np.vstack([L1_weights, L1_bias.reshape(1,-1)])\n",
    "\n",
    "print(w1_prog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 1 1]\n",
      " [1 0 1 0]\n",
      " [1 0 1 0]\n",
      " [1 0 1 0]\n",
      " [1 0 0 1]\n",
      " [0 1 0 1]\n",
      " [1 1 0 0]\n",
      " [0 1 0 1]]\n"
     ]
    }
   ],
   "source": [
    "print(L2_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(L2_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 1 1]\n",
      " [1 0 1 0]\n",
      " [1 0 1 0]\n",
      " [1 0 1 0]\n",
      " [1 0 0 1]\n",
      " [0 1 0 1]\n",
      " [1 1 0 0]\n",
      " [0 1 0 1]\n",
      " [0 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "w2_prog = np.vstack([L2_weights, L2_bias.reshape(1,-1)])\n",
    "\n",
    "print(w2_prog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pwl(time, 0us, 3V, 100us, 3V, 101us, 0V, 200us, 0V, 201us, 3V, 300us, 3V, 301us, 0.5V, 400us, 0.5V, 401us, 0V, 500us, 0V)\n"
     ]
    }
   ],
   "source": [
    "def generate_pwl(binary_string, rise_fall_time='1us', time_step='100us', high_voltage = 3, low_voltage = 0, read_high = 0.5, read_low = 0):\n",
    "    \"\"\"\n",
    "    Generate a PWL signal from a binary string with rise and fall times.\n",
    "\n",
    "    Parameters:\n",
    "    - binary_string (str): Binary string where '1' represents 1.5V and '0' represents 0V.\n",
    "    - rise_fall_time (str): Rise and fall time in microseconds (default '0.1us').\n",
    "    - time_step (str): Time step in microseconds (default '100us').\n",
    "\n",
    "    Returns:\n",
    "    - pwl_signal (str): A string representing the PWL signal.\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert 'rise_fall_time' and 'time_step' to float (in microseconds)\n",
    "    rise_fall_time = int(rise_fall_time.replace('us', ''))\n",
    "    time_step = int(time_step.replace('us', ''))\n",
    "\n",
    "    # Convert the binary string to a list of voltages: 1 -> 1.5V, 0 -> 0V\n",
    "    voltage_map_write = {'1': high_voltage, '0': low_voltage}\n",
    "    voltage_map_read = {'1': read_high, '0': read_low}\n",
    "    # Initialize PWL signal\n",
    "    pwl_signal = f\"pwl(time, 0us, {voltage_map_write[binary_string[0]]}V\"\n",
    "\n",
    "    # Current time in microseconds (start at 0)\n",
    "    current_time = 0\n",
    "    read_mode = False\n",
    "    # Iterate through the binary string and generate the PWL signal\n",
    "    for i in range(len(binary_string) - 1):\n",
    "        if binary_string[i] == 'x':\n",
    "            read_mode = True\n",
    "            continue\n",
    "        # print(binary_string[i])\n",
    "        if read_mode:\n",
    "            current_voltage = voltage_map_read[binary_string[i]]\n",
    "            next_voltage = voltage_map_read[binary_string[i + 1]]\n",
    "        else:\n",
    "            if  binary_string[i+1] == 'x':\n",
    "              current_voltage = voltage_map_write[binary_string[i]]\n",
    "              next_voltage = voltage_map_read[binary_string[i + 2]]\n",
    "            else:\n",
    "              current_voltage = voltage_map_write[binary_string[i]]\n",
    "              next_voltage = voltage_map_write[binary_string[i + 1]]\n",
    "\n",
    "        # Add the current point\n",
    "        pwl_signal += f\", {current_time+time_step}us, {current_voltage}V\"\n",
    "\n",
    "        # Transition time for rise or fall (0.1 us)\n",
    "        if current_voltage != next_voltage:\n",
    "            # Rise or fall from the current voltage to the next voltage\n",
    "            transition_time = current_time + rise_fall_time  # Midway for transition\n",
    "            pwl_signal += f\", {transition_time + time_step}us, {next_voltage}V\"\n",
    "\n",
    "        # Update time\n",
    "        current_time += time_step\n",
    "\n",
    "    # Add the last point (voltage for the last character in the binary string)\n",
    "    if read_mode:\n",
    "        final_voltage = voltage_map_read[binary_string[-1]]\n",
    "    else:\n",
    "        final_voltage = voltage_map_write[binary_string[-1]]\n",
    "    pwl_signal += f\", {current_time + time_step}us, {final_voltage}V\"\n",
    "\n",
    "    # Close the PWL signal string\n",
    "    pwl_signal += \")\"\n",
    "\n",
    "    return pwl_signal\n",
    "\n",
    "# Example usage:\n",
    "binary_string = \"101x10\"\n",
    "pwl_signal = generate_pwl(binary_string)\n",
    "\n",
    "# Output the generated PWL signal\n",
    "print(pwl_signal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pwl_array(weights, image):\n",
    "  pwl = {}\n",
    "  # print(image.shape)\n",
    "  if len(image.shape) == 3:\n",
    "    flattened_image = image.reshape(image.shape[0], -1)\n",
    "  elif len(image.shape) == 2:\n",
    "    flattened_image = np.array([image.reshape(-1)])\n",
    "  # print(flattened_image.shape)\n",
    "  for i in range(16):\n",
    "    bin_str = \"0\"*i + \"1\" + \"0\"*(15-i)\n",
    "    # print(bin_str)\n",
    "    bin_str += \"x\"\n",
    "    for j in range(flattened_image.shape[0]):\n",
    "      bin_str += str(flattened_image[j][i])\n",
    "    # print(bin_str)\n",
    "    pwl[f\"WL_{i}\"] = generate_pwl(bin_str, rise_fall_time='1us', time_step='100us', high_voltage = 3, low_voltage = 1)\n",
    "\n",
    "\n",
    "  for i in range(8):\n",
    "    bin_str = \"\"\n",
    "    for j in range(16):\n",
    "      bin_str += '1' if weights[i][j] > 0.5 else '0'       #ENTER CONDITION FOR WEIGHTS BINARISATION\n",
    "    bin_str += \"x\"\n",
    "    for j in range(flattened_image.shape[0]):\n",
    "      bin_str += \"0\"\n",
    "    pwl[f\"BL_{i}\"] = generate_pwl(bin_str, rise_fall_time='1us', time_step='100us', high_voltage = 0, low_voltage = 2, read_low = 0)\n",
    "\n",
    "  return pwl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 1 1 1]\n",
      " [0 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 1 0 0]\n",
      " [1 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 1]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 1 1 0 0 0 0 0]\n",
      " [0 1 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [1 0 0 1 0 0 0 0]\n",
      " [1 0 0 0 1 1 0 1]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0]\n",
      " [1 0 0 0 1 1 0 1]]\n"
     ]
    }
   ],
   "source": [
    "print(L1_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'WL_0': 'pwl(time, 0us, 3V, 100us, 3V, 101us, 1V, 200us, 1V, 300us, 1V, 400us, 1V, 500us, 1V, 600us, 1V, 700us, 1V, 800us, 1V, 900us, 1V, 1000us, 1V, 1100us, 1V, 1200us, 1V, 1300us, 1V, 1400us, 1V, 1500us, 1V, 1600us, 1V, 1601us, 0V, 1700us, 0V)',\n",
       " 'WL_1': 'pwl(time, 0us, 1V, 100us, 1V, 101us, 3V, 200us, 3V, 201us, 1V, 300us, 1V, 400us, 1V, 500us, 1V, 600us, 1V, 700us, 1V, 800us, 1V, 900us, 1V, 1000us, 1V, 1100us, 1V, 1200us, 1V, 1300us, 1V, 1400us, 1V, 1500us, 1V, 1600us, 1V, 1601us, 0.5V, 1700us, 0.5V)',\n",
       " 'WL_2': 'pwl(time, 0us, 1V, 100us, 1V, 200us, 1V, 201us, 3V, 300us, 3V, 301us, 1V, 400us, 1V, 500us, 1V, 600us, 1V, 700us, 1V, 800us, 1V, 900us, 1V, 1000us, 1V, 1100us, 1V, 1200us, 1V, 1300us, 1V, 1400us, 1V, 1500us, 1V, 1600us, 1V, 1601us, 0.5V, 1700us, 0.5V)',\n",
       " 'WL_3': 'pwl(time, 0us, 1V, 100us, 1V, 200us, 1V, 300us, 1V, 301us, 3V, 400us, 3V, 401us, 1V, 500us, 1V, 600us, 1V, 700us, 1V, 800us, 1V, 900us, 1V, 1000us, 1V, 1100us, 1V, 1200us, 1V, 1300us, 1V, 1400us, 1V, 1500us, 1V, 1600us, 1V, 1601us, 0V, 1700us, 0V)',\n",
       " 'WL_4': 'pwl(time, 0us, 1V, 100us, 1V, 200us, 1V, 300us, 1V, 400us, 1V, 401us, 3V, 500us, 3V, 501us, 1V, 600us, 1V, 700us, 1V, 800us, 1V, 900us, 1V, 1000us, 1V, 1100us, 1V, 1200us, 1V, 1300us, 1V, 1400us, 1V, 1500us, 1V, 1600us, 1V, 1601us, 0.5V, 1700us, 0.5V)',\n",
       " 'WL_5': 'pwl(time, 0us, 1V, 100us, 1V, 200us, 1V, 300us, 1V, 400us, 1V, 500us, 1V, 501us, 3V, 600us, 3V, 601us, 1V, 700us, 1V, 800us, 1V, 900us, 1V, 1000us, 1V, 1100us, 1V, 1200us, 1V, 1300us, 1V, 1400us, 1V, 1500us, 1V, 1600us, 1V, 1601us, 0V, 1700us, 0V)',\n",
       " 'WL_6': 'pwl(time, 0us, 1V, 100us, 1V, 200us, 1V, 300us, 1V, 400us, 1V, 500us, 1V, 600us, 1V, 601us, 3V, 700us, 3V, 701us, 1V, 800us, 1V, 900us, 1V, 1000us, 1V, 1100us, 1V, 1200us, 1V, 1300us, 1V, 1400us, 1V, 1500us, 1V, 1600us, 1V, 1601us, 0V, 1700us, 0V)',\n",
       " 'WL_7': 'pwl(time, 0us, 1V, 100us, 1V, 200us, 1V, 300us, 1V, 400us, 1V, 500us, 1V, 600us, 1V, 700us, 1V, 701us, 3V, 800us, 3V, 801us, 1V, 900us, 1V, 1000us, 1V, 1100us, 1V, 1200us, 1V, 1300us, 1V, 1400us, 1V, 1500us, 1V, 1600us, 1V, 1601us, 0.5V, 1700us, 0.5V)',\n",
       " 'WL_8': 'pwl(time, 0us, 1V, 100us, 1V, 200us, 1V, 300us, 1V, 400us, 1V, 500us, 1V, 600us, 1V, 700us, 1V, 800us, 1V, 801us, 3V, 900us, 3V, 901us, 1V, 1000us, 1V, 1100us, 1V, 1200us, 1V, 1300us, 1V, 1400us, 1V, 1500us, 1V, 1600us, 1V, 1601us, 0.5V, 1700us, 0.5V)',\n",
       " 'WL_9': 'pwl(time, 0us, 1V, 100us, 1V, 200us, 1V, 300us, 1V, 400us, 1V, 500us, 1V, 600us, 1V, 700us, 1V, 800us, 1V, 900us, 1V, 901us, 3V, 1000us, 3V, 1001us, 1V, 1100us, 1V, 1200us, 1V, 1300us, 1V, 1400us, 1V, 1500us, 1V, 1600us, 1V, 1601us, 0.5V, 1700us, 0.5V)',\n",
       " 'WL_10': 'pwl(time, 0us, 1V, 100us, 1V, 200us, 1V, 300us, 1V, 400us, 1V, 500us, 1V, 600us, 1V, 700us, 1V, 800us, 1V, 900us, 1V, 1000us, 1V, 1001us, 3V, 1100us, 3V, 1101us, 1V, 1200us, 1V, 1300us, 1V, 1400us, 1V, 1500us, 1V, 1600us, 1V, 1601us, 0.5V, 1700us, 0.5V)',\n",
       " 'WL_11': 'pwl(time, 0us, 1V, 100us, 1V, 200us, 1V, 300us, 1V, 400us, 1V, 500us, 1V, 600us, 1V, 700us, 1V, 800us, 1V, 900us, 1V, 1000us, 1V, 1100us, 1V, 1101us, 3V, 1200us, 3V, 1201us, 1V, 1300us, 1V, 1400us, 1V, 1500us, 1V, 1600us, 1V, 1601us, 0.5V, 1700us, 0.5V)',\n",
       " 'WL_12': 'pwl(time, 0us, 1V, 100us, 1V, 200us, 1V, 300us, 1V, 400us, 1V, 500us, 1V, 600us, 1V, 700us, 1V, 800us, 1V, 900us, 1V, 1000us, 1V, 1100us, 1V, 1200us, 1V, 1201us, 3V, 1300us, 3V, 1301us, 1V, 1400us, 1V, 1500us, 1V, 1600us, 1V, 1601us, 0.5V, 1700us, 0.5V)',\n",
       " 'WL_13': 'pwl(time, 0us, 1V, 100us, 1V, 200us, 1V, 300us, 1V, 400us, 1V, 500us, 1V, 600us, 1V, 700us, 1V, 800us, 1V, 900us, 1V, 1000us, 1V, 1100us, 1V, 1200us, 1V, 1300us, 1V, 1301us, 3V, 1400us, 3V, 1401us, 1V, 1500us, 1V, 1600us, 1V, 1601us, 0V, 1700us, 0V)',\n",
       " 'WL_14': 'pwl(time, 0us, 1V, 100us, 1V, 200us, 1V, 300us, 1V, 400us, 1V, 500us, 1V, 600us, 1V, 700us, 1V, 800us, 1V, 900us, 1V, 1000us, 1V, 1100us, 1V, 1200us, 1V, 1300us, 1V, 1400us, 1V, 1401us, 3V, 1500us, 3V, 1501us, 1V, 1600us, 1V, 1601us, 0V, 1700us, 0V)',\n",
       " 'WL_15': 'pwl(time, 0us, 1V, 100us, 1V, 200us, 1V, 300us, 1V, 400us, 1V, 500us, 1V, 600us, 1V, 700us, 1V, 800us, 1V, 900us, 1V, 1000us, 1V, 1100us, 1V, 1200us, 1V, 1300us, 1V, 1400us, 1V, 1500us, 1V, 1501us, 3V, 1600us, 3V, 1601us, 0.5V, 1700us, 0.5V)',\n",
       " 'BL_0': 'pwl(time, 0us, 2V, 100us, 2V, 200us, 2V, 300us, 2V, 400us, 2V, 401us, 0V, 500us, 0V, 501us, 2V, 600us, 2V, 700us, 2V, 800us, 2V, 900us, 2V, 1000us, 2V, 1100us, 2V, 1101us, 0V, 1200us, 0V, 1300us, 0V, 1301us, 2V, 1400us, 2V, 1500us, 2V, 1501us, 0V, 1600us, 0V, 1700us, 0V)',\n",
       " 'BL_1': 'pwl(time, 0us, 2V, 100us, 2V, 200us, 2V, 300us, 2V, 400us, 2V, 500us, 2V, 600us, 2V, 700us, 2V, 701us, 0V, 800us, 0V, 900us, 0V, 901us, 2V, 1000us, 2V, 1100us, 2V, 1200us, 2V, 1300us, 2V, 1400us, 2V, 1500us, 2V, 1600us, 2V, 1601us, 0V, 1700us, 0V)',\n",
       " 'BL_2': 'pwl(time, 0us, 2V, 100us, 2V, 200us, 2V, 300us, 2V, 400us, 2V, 500us, 2V, 600us, 2V, 700us, 2V, 701us, 0V, 800us, 0V, 900us, 0V, 901us, 2V, 1000us, 2V, 1100us, 2V, 1200us, 2V, 1300us, 2V, 1400us, 2V, 1500us, 2V, 1600us, 2V, 1601us, 0V, 1700us, 0V)',\n",
       " 'BL_3': 'pwl(time, 0us, 2V, 100us, 2V, 101us, 0V, 200us, 0V, 201us, 2V, 300us, 2V, 400us, 2V, 401us, 0V, 500us, 0V, 501us, 2V, 600us, 2V, 700us, 2V, 800us, 2V, 900us, 2V, 1000us, 2V, 1100us, 2V, 1101us, 0V, 1200us, 0V, 1201us, 2V, 1300us, 2V, 1400us, 2V, 1500us, 2V, 1600us, 2V, 1601us, 0V, 1700us, 0V)',\n",
       " 'BL_4': 'pwl(time, 0us, 2V, 100us, 2V, 200us, 2V, 300us, 2V, 400us, 2V, 500us, 2V, 600us, 2V, 700us, 2V, 800us, 2V, 900us, 2V, 1000us, 2V, 1100us, 2V, 1200us, 2V, 1201us, 0V, 1300us, 0V, 1301us, 2V, 1400us, 2V, 1500us, 2V, 1501us, 0V, 1600us, 0V, 1700us, 0V)',\n",
       " 'BL_5': 'pwl(time, 0us, 2V, 100us, 2V, 101us, 0V, 200us, 0V, 201us, 2V, 300us, 2V, 301us, 0V, 400us, 0V, 401us, 2V, 500us, 2V, 501us, 0V, 600us, 0V, 601us, 2V, 700us, 2V, 800us, 2V, 900us, 2V, 1000us, 2V, 1100us, 2V, 1200us, 2V, 1201us, 0V, 1300us, 0V, 1301us, 2V, 1400us, 2V, 1401us, 0V, 1500us, 0V, 1600us, 0V, 1700us, 0V)',\n",
       " 'BL_6': 'pwl(time, 0us, 2V, 100us, 2V, 101us, 0V, 200us, 0V, 300us, 0V, 301us, 2V, 400us, 2V, 500us, 2V, 600us, 2V, 700us, 2V, 800us, 2V, 900us, 2V, 1000us, 2V, 1100us, 2V, 1200us, 2V, 1300us, 2V, 1400us, 2V, 1500us, 2V, 1600us, 2V, 1601us, 0V, 1700us, 0V)',\n",
       " 'BL_7': 'pwl(time, 0us, 2V, 100us, 2V, 101us, 0V, 200us, 0V, 201us, 2V, 300us, 2V, 400us, 2V, 500us, 2V, 501us, 0V, 600us, 0V, 601us, 2V, 700us, 2V, 800us, 2V, 900us, 2V, 1000us, 2V, 1100us, 2V, 1200us, 2V, 1201us, 0V, 1300us, 0V, 1301us, 2V, 1400us, 2V, 1500us, 2V, 1501us, 0V, 1600us, 0V, 1700us, 0V)'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwl_array(L1_weights.T, img[0].reshape(4,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_10160\\920616709.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  X_train, y_train = torch.load(\"training_data_500.pt\")\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_10160\\920616709.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  X_val, y_val = torch.load(\"validation_data_60.pt\")\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_10160\\920616709.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  X_test, y_test = torch.load(\"testing_data_100.pt\")\n"
     ]
    }
   ],
   "source": [
    "# Load the saved datasets\n",
    "X_train, y_train = torch.load(\"training_data_500.pt\")\n",
    "X_val, y_val = torch.load(\"validation_data_60.pt\")\n",
    "X_test, y_test = torch.load(\"testing_data_100.pt\")\n",
    "\n",
    "# Create DataLoader for batching\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "val_dataset = TensorDataset(X_val, y_val)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Define the neural network model\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(16, 8)  # 16 input neurons, 8 hidden neurons\n",
    "        self.fc2 = nn.Linear(8, 4)   # 8 hidden neurons, 4 output neurons (for 4 classes)\n",
    "        self.activation = nn.Tanh()  # Activation function\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.fc1(x))\n",
    "        x = torch.clamp(x, min=0.0, max=1.0)  # Clamp outputs between 0 and 1\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SimpleNN()\n",
    "\n",
    "# Load the state dict into the model\n",
    "model.load_state_dict(torch.load(\"new_model.pth\", weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 71.00%\n"
     ]
    }
   ],
   "source": [
    "def test_model(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "# Test the trained model\n",
    "test_model(model, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
